
* Imperative programming uses a thread per request(Tomcat).
* Reactive programming uses a loop of events(Netty) with no blocking threads.

* Traditional JDBC uses blocking threads with HikariCP
* R2DBC uses a Reactive Connection Pool that keeps open connections (async)


01-process-transaction
02-notification-service
03-oauth2-jwt
04-observability-context-propagation
05-kafka-retries-backoff
06-transactional-outbox-pattern
07-docker-kubernetes


***********************************************************************

"Real-Time Fraud Alert System"

Componentes Técnicos de la Solución

1. Ingesta: Transaction-Producer (WebFlux + Kafka)
    En lugar de un controlador REST tradicional, este servicio manejará las transacciones entrantes de forma asíncrona.
    Tecnología: Spring WebFlux + Reactor Kafka.
    Clave: El uso de KafkaSender de Project Reactor permite que el envío del mensaje sea una operación no bloqueante que devuelve un Mono<SenderResult<Void>>.

2. El Cerebro: Fraud-Processor (Stream Processing)
    Este es el corazón reactivo. Consumirá el flujo de Kafka como un Flux<Transaction>.
    Estrategia de Ventana (Windowing): Podrías usar operadores como window() o buffer() para analizar, por ejemplo, si un usuario ha hecho más de 5 transacciones en los últimos 30 segundos (detección de patrones).
    Backpressure: Si Kafka envía datos más rápido de lo que tu lógica de fraude puede procesar, el flujo reactivo gestionará la demanda para no desbordar la memoria (Heap).

3. Persistencia: R2DBC y Redis Reactivo
    Aquí es donde muchos fallan. Si usas Hibernate tradicional (JDBC), bloqueas los hilos de Netty.
    R2DBC (Reactive Relational Database Connectivity): Para persistir las transacciones sospechosas en PostgreSQL sin bloquear.
    Spring Data Reactive Redis: Para consultar en milisegundos las "listas negras" o límites de crédito.

4. Observabilidad (Tu especialidad)
    Dado que en el mundo reactivo el "Stack Trace" tradicional se vuelve confuso (porque los hilos saltan de una tarea a otra), la arquitectura incluirá:
    Micrometer Tracing: Para propagar el traceId a través de los flujos asíncronos.
    Kibana/Dynatrace: Para monitorear el rendimiento de los Event Loops.

***********************************************************************

Levantar base de datos postgres:

sudo rm -rf postgres-reactive   ----> borrar carpeta con contenido
sudo mkdir postgres-reactive

sudo chown -R jchaconv:jchaconv /home/jchaconv/postgres-reactive   ---> dar permisos sudo
ls -ld postgres-reactive    --> ejecutar desde aquí /home/jchaconv/ para validar permisos

docker-compose up -d

Para testear:
docker exec -it reactive-postgres-banking psql -U user_banking -d fraud_db -c "SELECT customer_id, daily_max_amount FROM customer_limits;"
docker exec -it reactive-postgres-banking psql -U user_banking -d fraud_db -c "SELECT count(*) FROM transactions;"
docker exec -it reactive-postgres-banking psql -U user_banking -d fraud_db -c "SELECT * FROM transactions;"
docker exec -it reactive-postgres-banking psql -U user_banking -d fraud_db -c "SELECT * FROM transactions WHERE customer_id = 'CUST-001';"


Probar fraud-detection-service:

curl -X POST http://localhost:8081/api/v1/transactions \
-H "Content-Type: application/json" \
-d '{
    "transactionId": "TXN-2026-WEB-001",
    "customerId": "CUST-001",
    "accountId": "ACC-101",
    "amount": 500.00,
    "currency": "PEN",
    "operationType": "DEBIT",
    "channel": "WEB"
}'

docker exec -it reactive-postgres-banking psql -U user_banking -d fraud_db -c "SELECT * FROM customer_limits WHERE customer_id = 'CUST-001';"

docker exec -it reactive-postgres-banking psql -U user_banking -d fraud_db -c "SELECT * FROM outbox_events;"


-----------------------------------------

Configuración Kafka server:
       
- rm -rf /tmp/kafka-logs /tmp/zookeeper /tmp/kraft-combined-logs
- KAFKA_CLUSTER_ID="$(bin/kafka-storage.sh random-uuid)"
- echo $KAFKA_CLUSTER_ID
- bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties
- bin/kafka-server-start.sh config/kraft/server.properties

- bin/kafka-topics.sh --bootstrap-server localhost:9092 --list
- bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic fraud-detection-events --from-beginning

bin/kafka-console-consumer.sh --bootstrap-server 127.0.0.1:9092 \
--topic fraud-detection-events \
--from-beginning \
--formatter kafka.tools.DefaultMessageFormatter \
--property print.key=true \
--property print.value=true \
--property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer \
--property value.deserializer=org.apache.kafka.common.serialization.StringDeserializer


- bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic fraud-detection-events

- bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list

- bin/kafka-server-stop.sh

- to configure application.properties, for the wsl use: ip addr show, use the eth0  → spring.kafka.bootstrap-servers=172.30.84.55:9092
- edit server.properties with this:
    listeners=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
    advertised.listeners=PLAINTEXT://172.30.84.55:9092

- bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic fraud-detection-events-dlt --from-beginning

bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
--topic fraud-detection-events-dlt \
--from-beginning \
--property print.headers=true


-----------------------------------------

Levantar Redis:

docker run -d --name redis-banking -p 6379:6379 redis:latest

# Entrar al CLI del contenedor
docker exec -it redis-banking redis-cli
# 1. Listar todas las llaves (Cuidado en producción, es lento)
keys *
# 2. Buscar solo las de idempotencia
keys idempotency:txn:*
# 3. Ver el valor de una transacción específica
get idempotency:txn:TXN-ERROR-002
# 4. Ver cuánto tiempo de vida le queda (en segundos)
ttl idempotency:txn:TXN-ERROR-002

FLUSHALL   ---> para borrar todo

***********************************************************************

Para levantar todo el ecosistema:

sudo mkdir fraud-alert-system
sudo chown -R jchaconv:jchaconv /home/jchaconv/fraud-alert-system   ---> dar permisos sudo
ls -ld fraud-alert-system    --> ejecutar desde aquí /home/jchaconv/ para validar permisos

tener esta estructura:

fraud-alert-system/
├── auth-server/             (Carpeta del microservicio)
├── fraud-detection-service/ (Carpeta del microservicio)
├── notification-service/    (Carpeta del microservicio)
├── scripts/                 <-- AQUÍ pones el script
│   └── init.sql
└── docker-compose.yaml      <-- El YAML en la raíz

chmod 644 /home/jchaconv/fraud-alert-system/scripts/init.sql   ---> Permisos de ejecución: Asegúrate de que el archivo tenga permisos de lectura dentro de WSL
chmod +x auth-server/mvnw
chmod +x fraud-detection-service/mvnw
chmod +x notification-service/mvnw

docker-compose up --build -d     -----> cuando necesito compilar de nuevo las imágenes
docker-compose ps   --> verificar estados


Solo la primera vez: Recuerda que Postgres solo ejecuta los scripts en /docker-entrypoint-initdb.d/ la primera vez que se crea el volumen.
Si haces cambios en el init.sql y quieres que se reflejen, debes borrar el contenedor y su volumen:

docker-compose down   ----> para limpiar los containers
docker-compose up -d     ----> cuando solo hay cambios en el docker-compose.yaml

docker logs -f fraud-detection-service
docker logs -f notification-service
docker logs -f auth-server


docker exec kafka-banking /opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list
docker exec -it reactive-postgres-banking psql -U user_banking -d fraud_db
SELECT * FROM transactions WHERE customer_id = 'CUST-001';

docker exec -it redis-banking redis-cli

curl http://localhost:8081/actuator/health

poner en hosts: 127.0.0.1 auth-server para que se genere la firma con ese host y no con uno no autorizado como "localhost"

test outbox:

docker stop kafka-banking

docker exec -it reactive-postgres-banking psql -U user_banking -d fraud_db -c "SELECT * FROM transactions WHERE customer_id = 'CUST-001';"
docker exec -it reactive-postgres-banking psql -U user_banking -d fraud_db -c "SELECT * FROM outbox_events;"

docker start kafka-banking

---------------------------------------------------------

Kubernetes Config:

---------------------
Install kubectl:
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
chmod +x kubectl
sudo mv kubectl /usr/local/bin/

# Verifica con:
kubectl version --client
---------------------
Install Kind:

curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.22.0/kind-linux-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind
---------------------
Crear primer cluster:
kind create cluster --name banking-cluster

Validar acceso:
kubectl cluster-info
kubectl get nodes
---------------------
Crear namespace:
kubectl create namespace banking-ns
---------------------
Crear un ConfigMap -> usar banking-config.yaml
kubectl apply -f banking-config.yaml
---------------------
Para configurar Postgres
Persistent Volume Claim -> postgres-pvc.yaml -> le dice a K8S "Resérvame 1GB de disco que sobreviva a reinicios".
También se usará el archivo postgres-db.yaml

# 1. Aplicar los archivos
kubectl apply -f postgres-pvc.yaml
kubectl apply -f postgres-db.yaml

# 2. Verificar que el Pod esté corriendo
kubectl get pods -n banking-ns

# 3. Verificar el Service (Este es el que usará tu Java app)
kubectl get svc -n banking-ns

* Self-Healing:
Si ejecuto esto:
kubectl delete pod <nombre-del-pod-postgres> -n banking-ns
K8s creará uno nuevo automáticamente

---------------------

Construir imágenes para subir a Docker Hub

Configurar PAT en Docker Hub -> settings

docker login -u jchaconv   -> luego pedirá el token
docker logout

# 1. Construir la imagen (asegúrate de estar en la carpeta del proyecto)
docker build -t jchaconv/fraud-detection-service:latest .

# 2. Subirla a la nube (Push)
docker push jchaconv/fraud-detection-service:latest

Ver en la parte de repositories de Docker Hub la imagen subida.
---------------------
Config de Redis:
usar redis-k8s.yaml
kubectl apply -f redis-k8s.yaml
---------------------
Crear fraud-service-deployment.yaml
kubectl apply -f fraud-service-deployment.yaml
Verificar el estado:
# Ver si el pod está en Running o da error
kubectl get pods -n banking-ns

# Ver los logs de tu Spring Boot para confirmar conexión a DB y Redis
kubectl logs -f deployment/fraud-detection-app -n banking-ns

Como estoy usando wsl sale error para descargar de internet. Vamos a inyectar directamente
desde mi máquina al cluster:
# 1. Cargar Postgres
docker pull postgres:15-alpine
kind load docker-image postgres:15-alpine --name banking-cluster

# 2. Cargar Redis
docker pull redis:7-alpine
kind load docker-image redis:7-alpine --name banking-cluster

# 3. Cargar tu App
kind load docker-image jchaconv/fraud-detection-service:latest --name banking-cluster

esta línea debe estar en los archivos(solo los tres de abajo) yaml: imagePullPolicy: IfNotPresent

Reiniciar despliegues:
kubectl apply -f postgres-db.yaml
kubectl apply -f redis-k8s.yaml
kubectl apply -f fraud-service-deployment.yaml

Verificar:
kubectl get pods -n banking-ns

Meter bien el init.sql para la base de datos:
kubectl create configmap postgres-init-script --from-file=init.sql -n banking-ns

actualizar el archivo de postgres (ya lo tengo actualizado)

# 1. Borramos el despliegue actual
kubectl delete deployment postgres-db -n banking-ns

# 2. Borramos el PVC para limpiar los datos previos (OJO: Esto borra tus datos actuales)
kubectl delete pvc postgres-pvc -n banking-ns

# 3. Aplicamos todo de nuevo
kubectl apply -f postgres-pvc.yaml
kubectl apply -f postgres-db.yaml

kubectl logs -f deployment/postgres-db -n banking-ns
---------------------
Probar App:
Hacer tunnel primero
kubectl port-forward svc/fraud-detection-entrypoint 8081:8081 -n banking-ns
http://localhost:8081/actuator/health
---------------------
Config Kafka -> usar kafka-k8s.yaml
docker pull apache/kafka:3.7.0
kind load docker-image apache/kafka:3.7.0 --name banking-cluster
kubectl apply -f kafka-k8s.yaml

---------------------




***********************************************************************

Datos nuevos e importantes:

Reactive Streams: estándar, conjunto de 4 interfaces: Publisher, Subscriber, Subscription y Processor) que definen cómo deben fluir los datos de forma asíncrona y con Backpressure (capacidad del consumidor para avisar que está saturado).

Project Reactor,: Librería de Tipos,Flujos de datos (Mono/Flux)
Spring WebFlux: Framework Web, Peticiones HTTP, Rutas, API REST
RxJava: Librería de Tipos, Flujos de datos (Observable)

* ISO Codes: Usar mcc (Merchant Category Code) es vital; si un cliente de Lima compra en una joyería en Rusia 5 minutos después de comprar un café en San Isidro, tu lógica reactiva detectará el fraude de inmediato.
* Índices para no hacer full table scan sino ir a los registros adecuados en millis
* Configurar healt-check(docker-compose) para evitar caídas de app si la bd no está disponible o aún está levantando
* Non-blocking I/O: Al devolver Mono<TransactionEntity> en el Controller, el hilo de Netty no se queda esperando a que la base de datos responda. Se libera inmediatamente para atender otras peticiones y vuelve cuando los datos están listos.
* MDC (Mapped Diagnostic Context) - correlation id es necesario configurarlo porque se pierde en el contexto reactivo. Lo hice con deferContextual(se tendría que implementar en cada método). Y también con Micrometer.
* Persistable en el Entity para que Spring sepa si es un INSERT o UPDATE
* Mono.defer() En programación reactiva, si no usas defer, el código dentro del switchIfEmpty se prepararía (instanciaría) incluso si la transacción ya existe. defer asegura que la lógica de negocio solo se ejecute si realmente la transacción es nueva.
* http://localhost:8081/swagger-ui.html
* map: para conversiones simple sincronas | flatmap: para seguir realizando operaciones async
* El bean authorizationServerSecurityFilterChain en auth-server activa por defecto la url que da el token
* Micrometer Tracing basado en OpenTelemetry/Brave. Observabilidad, propagation context.
* traceId Es único para toda la transacción distribuida. Si la petición pasa por 5 microservicios, todos compartirán el mismo Trace ID. Sirve para correlacionar logs de distintos servicios.
* spanId Es único para cada bloque de trabajo (unidad lógica). 
* backoff: Es la estrategia de esperar un tiempo antes de reintentar una operación que falló.
* backpressure: Es un mecanismo donde el Consumidor le dice al Productor: "¡Oye, vas muy rápido, no puedo procesar tanto!". En WebFlux: Si tu base de datos es lenta y están llegando miles de peticiones HTTP,
  el driver R2DBC aplica backpressure hacia arriba para que Netty deje de aceptar nuevos bytes hasta que haya espacio en memoria.
* circuit breaker: Es un patrón que evita que una aplicación intente realizar una operación que probablemente va a fallar. Tiene 3 estados:
    - Closed (Cerrado): Todo bien, el tráfico fluye.
    - Open (Abierto): Hubo demasiados errores. El circuito se "rompe" y falla inmediatamente sin siquiera intentar llamar al servicio (protege los recursos).
    - Half-Open: Después de un tiempo, deja pasar unas pocas peticiones para ver si el servicio ya se recuperó.

* Transactional Outbox Pattern -> Outbox-First
* El Scheduler es el motor que garantiza que la "consistencia eventual" se cumpla: si el mensaje está en la tabla, tarde o temprano llegará a Kafka.

* Kind (Kubernetes in Docker): Es el más rápido para testing de CI/CD

***********************************************************************

Operadores

1. map
Se usa para transformar los elementos de un flujo uno a uno. Toma un valor, le aplica una función y devuelve el nuevo valor.

Analogía: Tienes una lista de precios en soles y los multiplicas todos por el tipo de cambio para obtenerlos en dólares.

Ejemplo:
Flux<String> nombres = Flux.just("julio", "chacon");
Flux<String> enMayusculas = nombres.map(n -> n.toUpperCase());
// Resultado: "JULIO", "CHACON"

------

2. flatMap
A diferencia de map, flatMap se usa cuando la transformación devuelve otro flujo (un Mono o Flux) en lugar de un valor simple. Es ideal para llamadas asíncronas encadenadas (como ir a la DB tras recibir un ID).

Dato clave: No garantiza el orden original de los elementos, ya que procesa las suscripciones en paralelo.

Ejemplo:
Flux<String> ids = Flux.just("ID-1", "ID-2");
Flux<User> usuarios = ids.flatMap(id -> service.findUserById(id)); 
// findUserById devuelve un Mono<User>, flatMap lo "aplana" para que no sea Flux<Mono<User>>

------

3. switchIfEmpty
Es el "Plan B". Si el flujo original llega al final sin haber emitido ningún dato (está vacío), este operador salta y ejecuta un flujo alternativo.

Uso común: Buscar en caché; si no hay nada, buscar en la base de datos de Oracle.

Ejemplo:
Mono<String> cache = Mono.empty();
Mono<String> resultado = cache.switchIfEmpty(Mono.just("Dato de la DB"));
// Resultado: "Dato de la DB"

-------

4. zip
Se utiliza para combinar dos o más flujos. Espera a que todos los flujos tengan un elemento disponible y luego los une en un nuevo objeto (como una Tuple o un objeto personalizado).

Analogía: Como una cremallera (zipper); necesitas ambos lados para avanzar.

Ejemplo:
Mono<String> nombre = Mono.just("Julio");
Mono<String> cargo = Mono.just("Backend Dev");

Mono<String> combinado = Mono.zip(nombre, cargo)
    .map(tuple -> tuple.getT1() + " es " + tuple.getT2());
// Resultado: "Julio es Backend Dev"